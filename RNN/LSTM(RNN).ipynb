{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM(RNN).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayushrai/Deep-Learning/blob/master/RNN/LSTM(RNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGuYMCEd0M8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "b5684fe3-6a42-4d17-a654-d06cf2eb1d20"
      },
      "source": [
        "#imports\n",
        "from tensorflow.keras.layers import Dense,LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISk-pKHX08SO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate data\n",
        "data = [[[i+j] for i in range(0,5)]for j in range(0,100)]\n",
        "target = [i+5 for i in range(0,100)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vROlaKfg1MEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert list into numpy array\n",
        "data = np.array(data,np.float32)/255\n",
        "target = np.array(target,np.float32)/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4HE8vtb2dw0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "716b6c0d-2f84-4806-cdf0-ec782b5d30f3"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LOhJTt427rC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split data for training and validation\n",
        "x_train,x_test,y_train,y_test = train_test_split(data,target,test_size =.2,random_state =4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3R26Tit1MvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "928d8ab1-8082-4c05-cd1c-6a8b95a772bc"
      },
      "source": [
        "#model\n",
        "model = Sequential()\n",
        "model.add(LSTM(1,input_shape=(5,1),return_sequences=True))\n",
        "model.add(LSTM(1,return_sequences=False))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn2epiYG8UqW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "aa3f1660-2b59-4389-d6b7-2d1374e1e6aa"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 5, 1)              12        \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1)                 12        \n",
            "=================================================================\n",
            "Total params: 24\n",
            "Trainable params: 24\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oLMqAxh3i1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"mean_absolute_error\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa7GShiP6N15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f07a6192-c7e2-4b01-9f04-cbf005b6348a"
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs=200,validation_data=(x_test,y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/200\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.1402 - acc: 0.0000e+00 - val_loss: 0.0988 - val_acc: 0.0000e+00\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 0s 865us/sample - loss: 0.1384 - acc: 0.0000e+00 - val_loss: 0.0981 - val_acc: 0.0000e+00\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 0s 952us/sample - loss: 0.1367 - acc: 0.0000e+00 - val_loss: 0.0974 - val_acc: 0.0000e+00\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 0s 933us/sample - loss: 0.1352 - acc: 0.0000e+00 - val_loss: 0.0967 - val_acc: 0.0000e+00\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 0s 958us/sample - loss: 0.1334 - acc: 0.0000e+00 - val_loss: 0.0960 - val_acc: 0.0000e+00\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.1320 - acc: 0.0000e+00 - val_loss: 0.0956 - val_acc: 0.0000e+00\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.1303 - acc: 0.0000e+00 - val_loss: 0.0952 - val_acc: 0.0000e+00\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 0s 884us/sample - loss: 0.1287 - acc: 0.0000e+00 - val_loss: 0.0948 - val_acc: 0.0000e+00\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 0s 852us/sample - loss: 0.1273 - acc: 0.0000e+00 - val_loss: 0.0945 - val_acc: 0.0000e+00\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 0s 964us/sample - loss: 0.1259 - acc: 0.0000e+00 - val_loss: 0.0941 - val_acc: 0.0000e+00\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 0s 893us/sample - loss: 0.1246 - acc: 0.0000e+00 - val_loss: 0.0938 - val_acc: 0.0000e+00\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 0s 897us/sample - loss: 0.1234 - acc: 0.0000e+00 - val_loss: 0.0934 - val_acc: 0.0000e+00\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 0s 926us/sample - loss: 0.1222 - acc: 0.0000e+00 - val_loss: 0.0931 - val_acc: 0.0000e+00\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 0s 890us/sample - loss: 0.1211 - acc: 0.0000e+00 - val_loss: 0.0928 - val_acc: 0.0000e+00\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 0s 880us/sample - loss: 0.1201 - acc: 0.0000e+00 - val_loss: 0.0928 - val_acc: 0.0000e+00\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 0s 930us/sample - loss: 0.1189 - acc: 0.0000e+00 - val_loss: 0.0927 - val_acc: 0.0000e+00\n",
            "Epoch 17/200\n",
            "80/80 [==============================] - 0s 874us/sample - loss: 0.1180 - acc: 0.0000e+00 - val_loss: 0.0928 - val_acc: 0.0000e+00\n",
            "Epoch 18/200\n",
            "80/80 [==============================] - 0s 921us/sample - loss: 0.1171 - acc: 0.0000e+00 - val_loss: 0.0930 - val_acc: 0.0000e+00\n",
            "Epoch 19/200\n",
            "80/80 [==============================] - 0s 953us/sample - loss: 0.1160 - acc: 0.0000e+00 - val_loss: 0.0932 - val_acc: 0.0000e+00\n",
            "Epoch 20/200\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.1152 - acc: 0.0000e+00 - val_loss: 0.0934 - val_acc: 0.0000e+00\n",
            "Epoch 21/200\n",
            "80/80 [==============================] - 0s 861us/sample - loss: 0.1143 - acc: 0.0000e+00 - val_loss: 0.0936 - val_acc: 0.0000e+00\n",
            "Epoch 22/200\n",
            "80/80 [==============================] - 0s 893us/sample - loss: 0.1136 - acc: 0.0000e+00 - val_loss: 0.0938 - val_acc: 0.0000e+00\n",
            "Epoch 23/200\n",
            "80/80 [==============================] - 0s 924us/sample - loss: 0.1129 - acc: 0.0000e+00 - val_loss: 0.0940 - val_acc: 0.0000e+00\n",
            "Epoch 24/200\n",
            "80/80 [==============================] - 0s 820us/sample - loss: 0.1122 - acc: 0.0000e+00 - val_loss: 0.0943 - val_acc: 0.0000e+00\n",
            "Epoch 25/200\n",
            "80/80 [==============================] - 0s 794us/sample - loss: 0.1116 - acc: 0.0000e+00 - val_loss: 0.0947 - val_acc: 0.0000e+00\n",
            "Epoch 26/200\n",
            "80/80 [==============================] - 0s 808us/sample - loss: 0.1110 - acc: 0.0000e+00 - val_loss: 0.0951 - val_acc: 0.0000e+00\n",
            "Epoch 27/200\n",
            "80/80 [==============================] - 0s 868us/sample - loss: 0.1104 - acc: 0.0000e+00 - val_loss: 0.0955 - val_acc: 0.0000e+00\n",
            "Epoch 28/200\n",
            "80/80 [==============================] - 0s 880us/sample - loss: 0.1099 - acc: 0.0000e+00 - val_loss: 0.0960 - val_acc: 0.0000e+00\n",
            "Epoch 29/200\n",
            "80/80 [==============================] - 0s 822us/sample - loss: 0.1093 - acc: 0.0000e+00 - val_loss: 0.0966 - val_acc: 0.0000e+00\n",
            "Epoch 30/200\n",
            "80/80 [==============================] - 0s 805us/sample - loss: 0.1087 - acc: 0.0000e+00 - val_loss: 0.0971 - val_acc: 0.0000e+00\n",
            "Epoch 31/200\n",
            "80/80 [==============================] - 0s 806us/sample - loss: 0.1082 - acc: 0.0000e+00 - val_loss: 0.0977 - val_acc: 0.0000e+00\n",
            "Epoch 32/200\n",
            "80/80 [==============================] - 0s 846us/sample - loss: 0.1077 - acc: 0.0000e+00 - val_loss: 0.0983 - val_acc: 0.0000e+00\n",
            "Epoch 33/200\n",
            "80/80 [==============================] - 0s 859us/sample - loss: 0.1072 - acc: 0.0000e+00 - val_loss: 0.0989 - val_acc: 0.0000e+00\n",
            "Epoch 34/200\n",
            "80/80 [==============================] - 0s 841us/sample - loss: 0.1069 - acc: 0.0000e+00 - val_loss: 0.0994 - val_acc: 0.0000e+00\n",
            "Epoch 35/200\n",
            "80/80 [==============================] - 0s 833us/sample - loss: 0.1066 - acc: 0.0000e+00 - val_loss: 0.1000 - val_acc: 0.0000e+00\n",
            "Epoch 36/200\n",
            "80/80 [==============================] - 0s 850us/sample - loss: 0.1061 - acc: 0.0000e+00 - val_loss: 0.1005 - val_acc: 0.0000e+00\n",
            "Epoch 37/200\n",
            "80/80 [==============================] - 0s 942us/sample - loss: 0.1058 - acc: 0.0000e+00 - val_loss: 0.1009 - val_acc: 0.0000e+00\n",
            "Epoch 38/200\n",
            "80/80 [==============================] - 0s 809us/sample - loss: 0.1055 - acc: 0.0000e+00 - val_loss: 0.1014 - val_acc: 0.0000e+00\n",
            "Epoch 39/200\n",
            "80/80 [==============================] - 0s 787us/sample - loss: 0.1052 - acc: 0.0000e+00 - val_loss: 0.1019 - val_acc: 0.0000e+00\n",
            "Epoch 40/200\n",
            "80/80 [==============================] - 0s 831us/sample - loss: 0.1050 - acc: 0.0000e+00 - val_loss: 0.1024 - val_acc: 0.0000e+00\n",
            "Epoch 41/200\n",
            "80/80 [==============================] - 0s 803us/sample - loss: 0.1047 - acc: 0.0000e+00 - val_loss: 0.1028 - val_acc: 0.0000e+00\n",
            "Epoch 42/200\n",
            "80/80 [==============================] - 0s 801us/sample - loss: 0.1045 - acc: 0.0000e+00 - val_loss: 0.1033 - val_acc: 0.0000e+00\n",
            "Epoch 43/200\n",
            "80/80 [==============================] - 0s 801us/sample - loss: 0.1043 - acc: 0.0000e+00 - val_loss: 0.1037 - val_acc: 0.0000e+00\n",
            "Epoch 44/200\n",
            "80/80 [==============================] - 0s 807us/sample - loss: 0.1041 - acc: 0.0000e+00 - val_loss: 0.1041 - val_acc: 0.0000e+00\n",
            "Epoch 45/200\n",
            "80/80 [==============================] - 0s 813us/sample - loss: 0.1039 - acc: 0.0000e+00 - val_loss: 0.1045 - val_acc: 0.0000e+00\n",
            "Epoch 46/200\n",
            "80/80 [==============================] - 0s 914us/sample - loss: 0.1037 - acc: 0.0000e+00 - val_loss: 0.1048 - val_acc: 0.0000e+00\n",
            "Epoch 47/200\n",
            "80/80 [==============================] - 0s 931us/sample - loss: 0.1036 - acc: 0.0000e+00 - val_loss: 0.1051 - val_acc: 0.0000e+00\n",
            "Epoch 48/200\n",
            "80/80 [==============================] - 0s 817us/sample - loss: 0.1034 - acc: 0.0000e+00 - val_loss: 0.1053 - val_acc: 0.0000e+00\n",
            "Epoch 49/200\n",
            "80/80 [==============================] - 0s 807us/sample - loss: 0.1033 - acc: 0.0000e+00 - val_loss: 0.1055 - val_acc: 0.0000e+00\n",
            "Epoch 50/200\n",
            "80/80 [==============================] - 0s 814us/sample - loss: 0.1032 - acc: 0.0000e+00 - val_loss: 0.1058 - val_acc: 0.0000e+00\n",
            "Epoch 51/200\n",
            "80/80 [==============================] - 0s 963us/sample - loss: 0.1031 - acc: 0.0000e+00 - val_loss: 0.1061 - val_acc: 0.0000e+00\n",
            "Epoch 52/200\n",
            "80/80 [==============================] - 0s 908us/sample - loss: 0.1029 - acc: 0.0000e+00 - val_loss: 0.1063 - val_acc: 0.0000e+00\n",
            "Epoch 53/200\n",
            "80/80 [==============================] - 0s 814us/sample - loss: 0.1028 - acc: 0.0000e+00 - val_loss: 0.1067 - val_acc: 0.0000e+00\n",
            "Epoch 54/200\n",
            "80/80 [==============================] - 0s 796us/sample - loss: 0.1027 - acc: 0.0000e+00 - val_loss: 0.1070 - val_acc: 0.0000e+00\n",
            "Epoch 55/200\n",
            "80/80 [==============================] - 0s 810us/sample - loss: 0.1026 - acc: 0.0000e+00 - val_loss: 0.1072 - val_acc: 0.0000e+00\n",
            "Epoch 56/200\n",
            "80/80 [==============================] - 0s 866us/sample - loss: 0.1026 - acc: 0.0000e+00 - val_loss: 0.1075 - val_acc: 0.0000e+00\n",
            "Epoch 57/200\n",
            "80/80 [==============================] - 0s 825us/sample - loss: 0.1024 - acc: 0.0000e+00 - val_loss: 0.1076 - val_acc: 0.0000e+00\n",
            "Epoch 58/200\n",
            "80/80 [==============================] - 0s 866us/sample - loss: 0.1023 - acc: 0.0000e+00 - val_loss: 0.1078 - val_acc: 0.0000e+00\n",
            "Epoch 59/200\n",
            "80/80 [==============================] - 0s 838us/sample - loss: 0.1023 - acc: 0.0000e+00 - val_loss: 0.1079 - val_acc: 0.0000e+00\n",
            "Epoch 60/200\n",
            "80/80 [==============================] - 0s 821us/sample - loss: 0.1022 - acc: 0.0000e+00 - val_loss: 0.1080 - val_acc: 0.0000e+00\n",
            "Epoch 61/200\n",
            "80/80 [==============================] - 0s 851us/sample - loss: 0.1021 - acc: 0.0000e+00 - val_loss: 0.1080 - val_acc: 0.0000e+00\n",
            "Epoch 62/200\n",
            "80/80 [==============================] - 0s 859us/sample - loss: 0.1020 - acc: 0.0000e+00 - val_loss: 0.1082 - val_acc: 0.0000e+00\n",
            "Epoch 63/200\n",
            "80/80 [==============================] - 0s 857us/sample - loss: 0.1019 - acc: 0.0000e+00 - val_loss: 0.1083 - val_acc: 0.0000e+00\n",
            "Epoch 64/200\n",
            "80/80 [==============================] - 0s 798us/sample - loss: 0.1019 - acc: 0.0000e+00 - val_loss: 0.1085 - val_acc: 0.0000e+00\n",
            "Epoch 65/200\n",
            "80/80 [==============================] - 0s 898us/sample - loss: 0.1018 - acc: 0.0000e+00 - val_loss: 0.1086 - val_acc: 0.0000e+00\n",
            "Epoch 66/200\n",
            "80/80 [==============================] - 0s 861us/sample - loss: 0.1017 - acc: 0.0000e+00 - val_loss: 0.1087 - val_acc: 0.0000e+00\n",
            "Epoch 67/200\n",
            "80/80 [==============================] - 0s 881us/sample - loss: 0.1016 - acc: 0.0000e+00 - val_loss: 0.1089 - val_acc: 0.0000e+00\n",
            "Epoch 68/200\n",
            "80/80 [==============================] - 0s 847us/sample - loss: 0.1016 - acc: 0.0000e+00 - val_loss: 0.1091 - val_acc: 0.0000e+00\n",
            "Epoch 69/200\n",
            "80/80 [==============================] - 0s 879us/sample - loss: 0.1015 - acc: 0.0000e+00 - val_loss: 0.1091 - val_acc: 0.0000e+00\n",
            "Epoch 70/200\n",
            "80/80 [==============================] - 0s 950us/sample - loss: 0.1014 - acc: 0.0000e+00 - val_loss: 0.1091 - val_acc: 0.0000e+00\n",
            "Epoch 71/200\n",
            "80/80 [==============================] - 0s 978us/sample - loss: 0.1014 - acc: 0.0000e+00 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
            "Epoch 72/200\n",
            "80/80 [==============================] - 0s 980us/sample - loss: 0.1013 - acc: 0.0000e+00 - val_loss: 0.1094 - val_acc: 0.0000e+00\n",
            "Epoch 73/200\n",
            "80/80 [==============================] - 0s 885us/sample - loss: 0.1012 - acc: 0.0000e+00 - val_loss: 0.1096 - val_acc: 0.0000e+00\n",
            "Epoch 74/200\n",
            "80/80 [==============================] - 0s 877us/sample - loss: 0.1012 - acc: 0.0000e+00 - val_loss: 0.1097 - val_acc: 0.0000e+00\n",
            "Epoch 75/200\n",
            "80/80 [==============================] - 0s 843us/sample - loss: 0.1011 - acc: 0.0000e+00 - val_loss: 0.1097 - val_acc: 0.0000e+00\n",
            "Epoch 76/200\n",
            "80/80 [==============================] - 0s 838us/sample - loss: 0.1010 - acc: 0.0000e+00 - val_loss: 0.1098 - val_acc: 0.0000e+00\n",
            "Epoch 77/200\n",
            "80/80 [==============================] - 0s 855us/sample - loss: 0.1010 - acc: 0.0000e+00 - val_loss: 0.1100 - val_acc: 0.0000e+00\n",
            "Epoch 78/200\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.1009 - acc: 0.0000e+00 - val_loss: 0.1101 - val_acc: 0.0000e+00\n",
            "Epoch 79/200\n",
            "80/80 [==============================] - 0s 877us/sample - loss: 0.1008 - acc: 0.0000e+00 - val_loss: 0.1103 - val_acc: 0.0000e+00\n",
            "Epoch 80/200\n",
            "80/80 [==============================] - 0s 851us/sample - loss: 0.1008 - acc: 0.0000e+00 - val_loss: 0.1105 - val_acc: 0.0000e+00\n",
            "Epoch 81/200\n",
            "80/80 [==============================] - 0s 867us/sample - loss: 0.1007 - acc: 0.0000e+00 - val_loss: 0.1108 - val_acc: 0.0000e+00\n",
            "Epoch 82/200\n",
            "80/80 [==============================] - 0s 881us/sample - loss: 0.1006 - acc: 0.0000e+00 - val_loss: 0.1108 - val_acc: 0.0000e+00\n",
            "Epoch 83/200\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.1006 - acc: 0.0000e+00 - val_loss: 0.1108 - val_acc: 0.0000e+00\n",
            "Epoch 84/200\n",
            "80/80 [==============================] - 0s 877us/sample - loss: 0.1005 - acc: 0.0000e+00 - val_loss: 0.1110 - val_acc: 0.0000e+00\n",
            "Epoch 85/200\n",
            "80/80 [==============================] - 0s 882us/sample - loss: 0.1005 - acc: 0.0000e+00 - val_loss: 0.1111 - val_acc: 0.0000e+00\n",
            "Epoch 86/200\n",
            "80/80 [==============================] - 0s 969us/sample - loss: 0.1004 - acc: 0.0000e+00 - val_loss: 0.1111 - val_acc: 0.0000e+00\n",
            "Epoch 87/200\n",
            "80/80 [==============================] - 0s 938us/sample - loss: 0.1004 - acc: 0.0000e+00 - val_loss: 0.1112 - val_acc: 0.0000e+00\n",
            "Epoch 88/200\n",
            "80/80 [==============================] - 0s 931us/sample - loss: 0.1003 - acc: 0.0000e+00 - val_loss: 0.1115 - val_acc: 0.0000e+00\n",
            "Epoch 89/200\n",
            "80/80 [==============================] - 0s 849us/sample - loss: 0.1003 - acc: 0.0000e+00 - val_loss: 0.1117 - val_acc: 0.0000e+00\n",
            "Epoch 90/200\n",
            "80/80 [==============================] - 0s 865us/sample - loss: 0.1002 - acc: 0.0000e+00 - val_loss: 0.1117 - val_acc: 0.0000e+00\n",
            "Epoch 91/200\n",
            "80/80 [==============================] - 0s 972us/sample - loss: 0.1002 - acc: 0.0000e+00 - val_loss: 0.1117 - val_acc: 0.0000e+00\n",
            "Epoch 92/200\n",
            "80/80 [==============================] - 0s 886us/sample - loss: 0.1001 - acc: 0.0000e+00 - val_loss: 0.1117 - val_acc: 0.0000e+00\n",
            "Epoch 93/200\n",
            "80/80 [==============================] - 0s 890us/sample - loss: 0.1001 - acc: 0.0000e+00 - val_loss: 0.1117 - val_acc: 0.0000e+00\n",
            "Epoch 94/200\n",
            "80/80 [==============================] - 0s 864us/sample - loss: 0.1000 - acc: 0.0000e+00 - val_loss: 0.1118 - val_acc: 0.0000e+00\n",
            "Epoch 95/200\n",
            "80/80 [==============================] - 0s 846us/sample - loss: 0.1000 - acc: 0.0000e+00 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
            "Epoch 96/200\n",
            "80/80 [==============================] - 0s 908us/sample - loss: 0.1000 - acc: 0.0000e+00 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
            "Epoch 97/200\n",
            "80/80 [==============================] - 0s 925us/sample - loss: 0.0999 - acc: 0.0000e+00 - val_loss: 0.1120 - val_acc: 0.0000e+00\n",
            "Epoch 98/200\n",
            "80/80 [==============================] - 0s 859us/sample - loss: 0.0999 - acc: 0.0000e+00 - val_loss: 0.1121 - val_acc: 0.0000e+00\n",
            "Epoch 99/200\n",
            "80/80 [==============================] - 0s 862us/sample - loss: 0.0998 - acc: 0.0000e+00 - val_loss: 0.1120 - val_acc: 0.0000e+00\n",
            "Epoch 100/200\n",
            "80/80 [==============================] - 0s 901us/sample - loss: 0.0998 - acc: 0.0000e+00 - val_loss: 0.1120 - val_acc: 0.0000e+00\n",
            "Epoch 101/200\n",
            "80/80 [==============================] - 0s 832us/sample - loss: 0.0997 - acc: 0.0000e+00 - val_loss: 0.1120 - val_acc: 0.0000e+00\n",
            "Epoch 102/200\n",
            "80/80 [==============================] - 0s 820us/sample - loss: 0.0997 - acc: 0.0000e+00 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
            "Epoch 103/200\n",
            "80/80 [==============================] - 0s 858us/sample - loss: 0.0997 - acc: 0.0000e+00 - val_loss: 0.1119 - val_acc: 0.0000e+00\n",
            "Epoch 104/200\n",
            "80/80 [==============================] - 0s 977us/sample - loss: 0.0996 - acc: 0.0000e+00 - val_loss: 0.1116 - val_acc: 0.0000e+00\n",
            "Epoch 105/200\n",
            "80/80 [==============================] - 0s 871us/sample - loss: 0.0996 - acc: 0.0000e+00 - val_loss: 0.1116 - val_acc: 0.0000e+00\n",
            "Epoch 106/200\n",
            "80/80 [==============================] - 0s 846us/sample - loss: 0.0995 - acc: 0.0000e+00 - val_loss: 0.1116 - val_acc: 0.0000e+00\n",
            "Epoch 107/200\n",
            "80/80 [==============================] - 0s 843us/sample - loss: 0.0995 - acc: 0.0000e+00 - val_loss: 0.1115 - val_acc: 0.0000e+00\n",
            "Epoch 108/200\n",
            "80/80 [==============================] - 0s 835us/sample - loss: 0.0995 - acc: 0.0000e+00 - val_loss: 0.1115 - val_acc: 0.0000e+00\n",
            "Epoch 109/200\n",
            "80/80 [==============================] - 0s 919us/sample - loss: 0.0994 - acc: 0.0000e+00 - val_loss: 0.1116 - val_acc: 0.0000e+00\n",
            "Epoch 110/200\n",
            "80/80 [==============================] - 0s 972us/sample - loss: 0.0994 - acc: 0.0000e+00 - val_loss: 0.1116 - val_acc: 0.0000e+00\n",
            "Epoch 111/200\n",
            "80/80 [==============================] - 0s 968us/sample - loss: 0.0993 - acc: 0.0000e+00 - val_loss: 0.1115 - val_acc: 0.0000e+00\n",
            "Epoch 112/200\n",
            "80/80 [==============================] - 0s 846us/sample - loss: 0.0993 - acc: 0.0000e+00 - val_loss: 0.1116 - val_acc: 0.0000e+00\n",
            "Epoch 113/200\n",
            "80/80 [==============================] - 0s 843us/sample - loss: 0.0993 - acc: 0.0000e+00 - val_loss: 0.1115 - val_acc: 0.0000e+00\n",
            "Epoch 114/200\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0992 - acc: 0.0000e+00 - val_loss: 0.1115 - val_acc: 0.0000e+00\n",
            "Epoch 115/200\n",
            "80/80 [==============================] - 0s 864us/sample - loss: 0.0992 - acc: 0.0000e+00 - val_loss: 0.1115 - val_acc: 0.0000e+00\n",
            "Epoch 116/200\n",
            "80/80 [==============================] - 0s 839us/sample - loss: 0.0992 - acc: 0.0000e+00 - val_loss: 0.1113 - val_acc: 0.0000e+00\n",
            "Epoch 117/200\n",
            "80/80 [==============================] - 0s 836us/sample - loss: 0.0991 - acc: 0.0000e+00 - val_loss: 0.1110 - val_acc: 0.0000e+00\n",
            "Epoch 118/200\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0991 - acc: 0.0000e+00 - val_loss: 0.1108 - val_acc: 0.0000e+00\n",
            "Epoch 119/200\n",
            "80/80 [==============================] - 0s 848us/sample - loss: 0.0991 - acc: 0.0000e+00 - val_loss: 0.1108 - val_acc: 0.0000e+00\n",
            "Epoch 120/200\n",
            "80/80 [==============================] - 0s 872us/sample - loss: 0.0990 - acc: 0.0000e+00 - val_loss: 0.1105 - val_acc: 0.0000e+00\n",
            "Epoch 121/200\n",
            "80/80 [==============================] - 0s 835us/sample - loss: 0.0990 - acc: 0.0000e+00 - val_loss: 0.1103 - val_acc: 0.0000e+00\n",
            "Epoch 122/200\n",
            "80/80 [==============================] - 0s 955us/sample - loss: 0.0989 - acc: 0.0000e+00 - val_loss: 0.1104 - val_acc: 0.0000e+00\n",
            "Epoch 123/200\n",
            "80/80 [==============================] - 0s 881us/sample - loss: 0.0989 - acc: 0.0000e+00 - val_loss: 0.1105 - val_acc: 0.0000e+00\n",
            "Epoch 124/200\n",
            "80/80 [==============================] - 0s 937us/sample - loss: 0.0989 - acc: 0.0000e+00 - val_loss: 0.1105 - val_acc: 0.0000e+00\n",
            "Epoch 125/200\n",
            "80/80 [==============================] - 0s 883us/sample - loss: 0.0988 - acc: 0.0000e+00 - val_loss: 0.1103 - val_acc: 0.0000e+00\n",
            "Epoch 126/200\n",
            "80/80 [==============================] - 0s 851us/sample - loss: 0.0988 - acc: 0.0000e+00 - val_loss: 0.1101 - val_acc: 0.0000e+00\n",
            "Epoch 127/200\n",
            "80/80 [==============================] - 0s 861us/sample - loss: 0.0988 - acc: 0.0000e+00 - val_loss: 0.1098 - val_acc: 0.0000e+00\n",
            "Epoch 128/200\n",
            "80/80 [==============================] - 0s 825us/sample - loss: 0.0987 - acc: 0.0000e+00 - val_loss: 0.1096 - val_acc: 0.0000e+00\n",
            "Epoch 129/200\n",
            "80/80 [==============================] - 0s 811us/sample - loss: 0.0987 - acc: 0.0000e+00 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
            "Epoch 130/200\n",
            "80/80 [==============================] - 0s 882us/sample - loss: 0.0987 - acc: 0.0000e+00 - val_loss: 0.1090 - val_acc: 0.0000e+00\n",
            "Epoch 131/200\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0987 - acc: 0.0000e+00 - val_loss: 0.1087 - val_acc: 0.0000e+00\n",
            "Epoch 132/200\n",
            "80/80 [==============================] - 0s 876us/sample - loss: 0.0986 - acc: 0.0000e+00 - val_loss: 0.1087 - val_acc: 0.0000e+00\n",
            "Epoch 133/200\n",
            "80/80 [==============================] - 0s 854us/sample - loss: 0.0986 - acc: 0.0000e+00 - val_loss: 0.1085 - val_acc: 0.0000e+00\n",
            "Epoch 134/200\n",
            "80/80 [==============================] - 0s 870us/sample - loss: 0.0986 - acc: 0.0000e+00 - val_loss: 0.1084 - val_acc: 0.0000e+00\n",
            "Epoch 135/200\n",
            "80/80 [==============================] - 0s 905us/sample - loss: 0.0986 - acc: 0.0000e+00 - val_loss: 0.1084 - val_acc: 0.0000e+00\n",
            "Epoch 136/200\n",
            "80/80 [==============================] - 0s 927us/sample - loss: 0.0985 - acc: 0.0000e+00 - val_loss: 0.1085 - val_acc: 0.0000e+00\n",
            "Epoch 137/200\n",
            "80/80 [==============================] - 0s 881us/sample - loss: 0.0985 - acc: 0.0000e+00 - val_loss: 0.1087 - val_acc: 0.0000e+00\n",
            "Epoch 138/200\n",
            "80/80 [==============================] - 0s 914us/sample - loss: 0.0985 - acc: 0.0000e+00 - val_loss: 0.1086 - val_acc: 0.0000e+00\n",
            "Epoch 139/200\n",
            "80/80 [==============================] - 0s 859us/sample - loss: 0.0984 - acc: 0.0000e+00 - val_loss: 0.1086 - val_acc: 0.0000e+00\n",
            "Epoch 140/200\n",
            "80/80 [==============================] - 0s 920us/sample - loss: 0.0984 - acc: 0.0000e+00 - val_loss: 0.1087 - val_acc: 0.0000e+00\n",
            "Epoch 141/200\n",
            "80/80 [==============================] - 0s 908us/sample - loss: 0.0984 - acc: 0.0000e+00 - val_loss: 0.1087 - val_acc: 0.0000e+00\n",
            "Epoch 142/200\n",
            "80/80 [==============================] - 0s 844us/sample - loss: 0.0983 - acc: 0.0000e+00 - val_loss: 0.1087 - val_acc: 0.0000e+00\n",
            "Epoch 143/200\n",
            "80/80 [==============================] - 0s 879us/sample - loss: 0.0983 - acc: 0.0000e+00 - val_loss: 0.1087 - val_acc: 0.0000e+00\n",
            "Epoch 144/200\n",
            "80/80 [==============================] - 0s 956us/sample - loss: 0.0983 - acc: 0.0000e+00 - val_loss: 0.1085 - val_acc: 0.0000e+00\n",
            "Epoch 145/200\n",
            "80/80 [==============================] - 0s 854us/sample - loss: 0.0983 - acc: 0.0000e+00 - val_loss: 0.1083 - val_acc: 0.0000e+00\n",
            "Epoch 146/200\n",
            "80/80 [==============================] - 0s 924us/sample - loss: 0.0982 - acc: 0.0000e+00 - val_loss: 0.1081 - val_acc: 0.0000e+00\n",
            "Epoch 147/200\n",
            "80/80 [==============================] - 0s 881us/sample - loss: 0.0982 - acc: 0.0000e+00 - val_loss: 0.1079 - val_acc: 0.0000e+00\n",
            "Epoch 148/200\n",
            "80/80 [==============================] - 0s 918us/sample - loss: 0.0982 - acc: 0.0000e+00 - val_loss: 0.1078 - val_acc: 0.0000e+00\n",
            "Epoch 149/200\n",
            "80/80 [==============================] - 0s 845us/sample - loss: 0.0982 - acc: 0.0000e+00 - val_loss: 0.1078 - val_acc: 0.0000e+00\n",
            "Epoch 150/200\n",
            "80/80 [==============================] - 0s 930us/sample - loss: 0.0982 - acc: 0.0000e+00 - val_loss: 0.1081 - val_acc: 0.0000e+00\n",
            "Epoch 151/200\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0981 - acc: 0.0000e+00 - val_loss: 0.1081 - val_acc: 0.0000e+00\n",
            "Epoch 152/200\n",
            "80/80 [==============================] - 0s 825us/sample - loss: 0.0981 - acc: 0.0000e+00 - val_loss: 0.1083 - val_acc: 0.0000e+00\n",
            "Epoch 153/200\n",
            "80/80 [==============================] - 0s 832us/sample - loss: 0.0981 - acc: 0.0000e+00 - val_loss: 0.1084 - val_acc: 0.0000e+00\n",
            "Epoch 154/200\n",
            "80/80 [==============================] - 0s 848us/sample - loss: 0.0980 - acc: 0.0000e+00 - val_loss: 0.1085 - val_acc: 0.0000e+00\n",
            "Epoch 155/200\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0980 - acc: 0.0000e+00 - val_loss: 0.1087 - val_acc: 0.0000e+00\n",
            "Epoch 156/200\n",
            "80/80 [==============================] - 0s 940us/sample - loss: 0.0980 - acc: 0.0000e+00 - val_loss: 0.1089 - val_acc: 0.0000e+00\n",
            "Epoch 157/200\n",
            "80/80 [==============================] - 0s 980us/sample - loss: 0.0980 - acc: 0.0000e+00 - val_loss: 0.1090 - val_acc: 0.0000e+00\n",
            "Epoch 158/200\n",
            "80/80 [==============================] - 0s 889us/sample - loss: 0.0979 - acc: 0.0000e+00 - val_loss: 0.1091 - val_acc: 0.0000e+00\n",
            "Epoch 159/200\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0979 - acc: 0.0000e+00 - val_loss: 0.1092 - val_acc: 0.0000e+00\n",
            "Epoch 160/200\n",
            "80/80 [==============================] - 0s 979us/sample - loss: 0.0979 - acc: 0.0000e+00 - val_loss: 0.1092 - val_acc: 0.0000e+00\n",
            "Epoch 161/200\n",
            "80/80 [==============================] - 0s 889us/sample - loss: 0.0979 - acc: 0.0000e+00 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
            "Epoch 162/200\n",
            "80/80 [==============================] - 0s 904us/sample - loss: 0.0978 - acc: 0.0000e+00 - val_loss: 0.1094 - val_acc: 0.0000e+00\n",
            "Epoch 163/200\n",
            "80/80 [==============================] - 0s 852us/sample - loss: 0.0978 - acc: 0.0000e+00 - val_loss: 0.1094 - val_acc: 0.0000e+00\n",
            "Epoch 164/200\n",
            "80/80 [==============================] - 0s 857us/sample - loss: 0.0978 - acc: 0.0000e+00 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
            "Epoch 165/200\n",
            "80/80 [==============================] - 0s 885us/sample - loss: 0.0978 - acc: 0.0000e+00 - val_loss: 0.1094 - val_acc: 0.0000e+00\n",
            "Epoch 166/200\n",
            "80/80 [==============================] - 0s 838us/sample - loss: 0.0977 - acc: 0.0000e+00 - val_loss: 0.1094 - val_acc: 0.0000e+00\n",
            "Epoch 167/200\n",
            "80/80 [==============================] - 0s 844us/sample - loss: 0.0977 - acc: 0.0000e+00 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
            "Epoch 168/200\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0977 - acc: 0.0000e+00 - val_loss: 0.1091 - val_acc: 0.0000e+00\n",
            "Epoch 169/200\n",
            "80/80 [==============================] - 0s 849us/sample - loss: 0.0977 - acc: 0.0000e+00 - val_loss: 0.1090 - val_acc: 0.0000e+00\n",
            "Epoch 170/200\n",
            "80/80 [==============================] - 0s 974us/sample - loss: 0.0977 - acc: 0.0000e+00 - val_loss: 0.1092 - val_acc: 0.0000e+00\n",
            "Epoch 171/200\n",
            "80/80 [==============================] - 0s 826us/sample - loss: 0.0976 - acc: 0.0000e+00 - val_loss: 0.1092 - val_acc: 0.0000e+00\n",
            "Epoch 172/200\n",
            "80/80 [==============================] - 0s 892us/sample - loss: 0.0976 - acc: 0.0000e+00 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
            "Epoch 173/200\n",
            "80/80 [==============================] - 0s 877us/sample - loss: 0.0976 - acc: 0.0000e+00 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
            "Epoch 174/200\n",
            "80/80 [==============================] - 0s 816us/sample - loss: 0.0976 - acc: 0.0000e+00 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
            "Epoch 175/200\n",
            "80/80 [==============================] - 0s 877us/sample - loss: 0.0975 - acc: 0.0000e+00 - val_loss: 0.1094 - val_acc: 0.0000e+00\n",
            "Epoch 176/200\n",
            "80/80 [==============================] - 0s 866us/sample - loss: 0.0975 - acc: 0.0000e+00 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
            "Epoch 177/200\n",
            "80/80 [==============================] - 0s 906us/sample - loss: 0.0975 - acc: 0.0000e+00 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
            "Epoch 178/200\n",
            "80/80 [==============================] - 0s 930us/sample - loss: 0.0975 - acc: 0.0000e+00 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
            "Epoch 179/200\n",
            "80/80 [==============================] - 0s 903us/sample - loss: 0.0975 - acc: 0.0000e+00 - val_loss: 0.1094 - val_acc: 0.0000e+00\n",
            "Epoch 180/200\n",
            "80/80 [==============================] - 0s 884us/sample - loss: 0.0974 - acc: 0.0000e+00 - val_loss: 0.1095 - val_acc: 0.0000e+00\n",
            "Epoch 181/200\n",
            "80/80 [==============================] - 0s 871us/sample - loss: 0.0974 - acc: 0.0000e+00 - val_loss: 0.1096 - val_acc: 0.0000e+00\n",
            "Epoch 182/200\n",
            "80/80 [==============================] - 0s 1000us/sample - loss: 0.0974 - acc: 0.0000e+00 - val_loss: 0.1098 - val_acc: 0.0000e+00\n",
            "Epoch 183/200\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0974 - acc: 0.0000e+00 - val_loss: 0.1100 - val_acc: 0.0000e+00\n",
            "Epoch 184/200\n",
            "80/80 [==============================] - 0s 851us/sample - loss: 0.0974 - acc: 0.0000e+00 - val_loss: 0.1100 - val_acc: 0.0000e+00\n",
            "Epoch 185/200\n",
            "80/80 [==============================] - 0s 862us/sample - loss: 0.0973 - acc: 0.0000e+00 - val_loss: 0.1099 - val_acc: 0.0000e+00\n",
            "Epoch 186/200\n",
            "80/80 [==============================] - 0s 915us/sample - loss: 0.0973 - acc: 0.0000e+00 - val_loss: 0.1098 - val_acc: 0.0000e+00\n",
            "Epoch 187/200\n",
            "80/80 [==============================] - 0s 862us/sample - loss: 0.0973 - acc: 0.0000e+00 - val_loss: 0.1095 - val_acc: 0.0000e+00\n",
            "Epoch 188/200\n",
            "80/80 [==============================] - 0s 877us/sample - loss: 0.0973 - acc: 0.0000e+00 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
            "Epoch 189/200\n",
            "80/80 [==============================] - 0s 824us/sample - loss: 0.0972 - acc: 0.0000e+00 - val_loss: 0.1090 - val_acc: 0.0000e+00\n",
            "Epoch 190/200\n",
            "80/80 [==============================] - 0s 806us/sample - loss: 0.0972 - acc: 0.0000e+00 - val_loss: 0.1086 - val_acc: 0.0000e+00\n",
            "Epoch 191/200\n",
            "80/80 [==============================] - 0s 859us/sample - loss: 0.0972 - acc: 0.0000e+00 - val_loss: 0.1084 - val_acc: 0.0000e+00\n",
            "Epoch 192/200\n",
            "80/80 [==============================] - 0s 910us/sample - loss: 0.0972 - acc: 0.0000e+00 - val_loss: 0.1082 - val_acc: 0.0000e+00\n",
            "Epoch 193/200\n",
            "80/80 [==============================] - 0s 886us/sample - loss: 0.0971 - acc: 0.0000e+00 - val_loss: 0.1082 - val_acc: 0.0000e+00\n",
            "Epoch 194/200\n",
            "80/80 [==============================] - 0s 1ms/sample - loss: 0.0971 - acc: 0.0000e+00 - val_loss: 0.1080 - val_acc: 0.0000e+00\n",
            "Epoch 195/200\n",
            "80/80 [==============================] - 0s 885us/sample - loss: 0.0971 - acc: 0.0000e+00 - val_loss: 0.1078 - val_acc: 0.0000e+00\n",
            "Epoch 196/200\n",
            "80/80 [==============================] - 0s 842us/sample - loss: 0.0971 - acc: 0.0000e+00 - val_loss: 0.1076 - val_acc: 0.0000e+00\n",
            "Epoch 197/200\n",
            "80/80 [==============================] - 0s 991us/sample - loss: 0.0971 - acc: 0.0000e+00 - val_loss: 0.1073 - val_acc: 0.0000e+00\n",
            "Epoch 198/200\n",
            "80/80 [==============================] - 0s 909us/sample - loss: 0.0970 - acc: 0.0000e+00 - val_loss: 0.1072 - val_acc: 0.0000e+00\n",
            "Epoch 199/200\n",
            "80/80 [==============================] - 0s 815us/sample - loss: 0.0970 - acc: 0.0000e+00 - val_loss: 0.1071 - val_acc: 0.0000e+00\n",
            "Epoch 200/200\n",
            "80/80 [==============================] - 0s 868us/sample - loss: 0.0970 - acc: 0.0000e+00 - val_loss: 0.1070 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMklYnLl7ZDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXAQsEpj6jo0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "f79cebe3-cd6f-46d3-9d67-16a3aecb73fa"
      },
      "source": [
        "plt.scatter(range(20),result,c=\"r\")\n",
        "plt.scatter(range(20),y_test,c=\"g\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f56d004f4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzPg/wFvVmVOU9Q0fQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBxkFrck7WHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "949b1dd8-770a-4328-cade-c77e4f60608f"
      },
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwCnoRUQCTkEvIhJwCnoRkYD7/0KCUHT0i0bgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_9umwu_8B0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}